#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼ è®ºåˆ†æä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç¼ è®ºåˆ†ææ¨¡å—è¿›è¡Œè‚¡ç¥¨æŠ€æœ¯åˆ†æ
"""

import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from analyzers.chanlun_analyzer import ChanLunAnalyzer, analyze_stock_chanlun
from data_provider.akshare_fetcher import AkshareFetcher
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)


def analyze_stock_with_chanlun(stock_code: str):
    """ä½¿ç”¨ç¼ è®ºåˆ†ææŒ‡å®šè‚¡ç¥¨"""
    print(f"ğŸŒŠ å¯¹ {stock_code} è¿›è¡Œç¼ è®ºåˆ†æ")
    print("=" * 60)

    try:
        # è·å–è‚¡ç¥¨æ•°æ®
        fetcher = AkshareFetcher()
        df, source = fetcher.get_daily_data(stock_code, days=120)

        if df is None or len(df) < 30:
            print(f"âŒ æ— æ³•è·å– {stock_code} çš„æ•°æ®")
            return

        print(f"ğŸ“Š æ•°æ®æ¥æº: {source}")
        print(f"ğŸ“ˆ æ•°æ®èŒƒå›´: {df['date'].iloc[0]} è‡³ {df['date'].iloc[-1]}")
        print(f"ğŸ“ æ•°æ®é•¿åº¦: {len(df)} æ¡Kçº¿")
        print(f"ğŸ’° ä»·æ ¼åŒºé—´: {df['low'].min():.2f} - {df['high'].max():.2f}")

        # è¿›è¡Œç¼ è®ºåˆ†æ
        result = analyze_stock_chanlun(df)

        if not result:
            print("âŒ ç¼ è®ºåˆ†æå¤±è´¥")
            return

        # æ˜¾ç¤ºåˆ†æç»“æœ
        print(f"\nğŸ” ç¼ è®ºåˆ†æç»“æœ:")
        print(f"åˆ†å‹æ•°é‡: {len(result.get('fenxings', []))}")
        print(f"ç¬”æ•°é‡: {len(result.get('bis', []))}")
        print(f"ä¸­æ¢æ•°é‡: {len(result.get('zhongshus', []))}")
        print(f"ä¹°å–ç‚¹æ•°é‡: {len(result.get('buy_sell_points', []))}")
        print(f"èµ°åŠ¿ç±»å‹: {result.get('trend_type', 'æœªçŸ¥')}")
        print(f"ç¼ è®ºè¯„åˆ†: {result.get('chanlun_score', 0):.1f}/100")

        # è¯¦ç»†åˆ†å‹ä¿¡æ¯
        fenxings = result.get('fenxings', [])
        if fenxings:
            print(f"\nğŸ“ æœ€è¿‘5ä¸ªåˆ†å‹:")
            for fx in fenxings[-5:]:
                emoji = "ğŸ”º" if fx.type.value == "é¡¶åˆ†å‹" else "ğŸ”»"
                print(f"  {emoji} {fx.date}: {fx.type.value} @ {fx.price:.2f}")

        # ä¸­æ¢ä¿¡æ¯
        zhongshus = result.get('zhongshus', [])
        if zhongshus:
            print(f"\nğŸ¯ ä¸­æ¢ä¿¡æ¯:")
            for i, zs in enumerate(zhongshus[-3:], 1):  # æ˜¾ç¤ºæœ€è¿‘3ä¸ªä¸­æ¢
                print(f"  ä¸­æ¢{i}: [{zs.low:.2f} - {zs.high:.2f}] (åŒ…å«{zs.bi_count}ç¬”)")

        # ä¹°å–ç‚¹ä¿¡æ¯
        buy_sell_points = result.get('buy_sell_points', [])
        if buy_sell_points:
            print(f"\nğŸ’° æœ€è¿‘ä¹°å–ç‚¹:")
            recent_points = buy_sell_points[-5:]  # æœ€è¿‘5ä¸ªç‚¹
            for point in recent_points:
                emoji = "ğŸŸ¢" if "ä¹°" in point.type.value else "ğŸ”´"
                print(f"  {emoji} {point.date}: {point.type.value} @ {point.price:.2f}")
                print(f"     ç½®ä¿¡åº¦: {point.confidence:.1f}, åŸå› : {point.reason}")

        # èƒŒé©°åˆ†æ
        beichi = result.get('beichi_analysis', {})
        if beichi.get('has_beichi'):
            emoji = "âš ï¸" if beichi.get('type') == "ä¸Šæ¶¨èƒŒé©°" else "ğŸ’¡"
            print(f"\n{emoji} èƒŒé©°åˆ†æ: {beichi.get('type')}")
            print(f"   èƒŒé©°å¼ºåº¦: {beichi.get('strength', 0):.2f}")
        else:
            print(f"\nâœ… èƒŒé©°åˆ†æ: å½“å‰æ— æ˜æ˜¾èƒŒé©°")

        # æŠ•èµ„å»ºè®®
        print(f"\nğŸ’¡ ç¼ è®ºæŠ•èµ„å»ºè®®:")
        score = result.get('chanlun_score', 50)
        trend = result.get('trend_type', '')

        if score >= 70:
            print("   ğŸ”¥ å¼ºçƒˆæ¨è: ç¼ è®ºä¿¡å·ç§¯æï¼Œé€‚åˆä¹°å…¥")
        elif score >= 60:
            print("   ğŸŸ¢ æ¨è: ç¼ è®ºä¿¡å·è¾ƒå¥½ï¼Œå¯ä»¥è€ƒè™‘ä¹°å…¥")
        elif score >= 40:
            print("   ğŸŸ¡ è§‚æœ›: ç¼ è®ºä¿¡å·ä¸­æ€§ï¼Œå»ºè®®ç­‰å¾…æ›´å¥½æ—¶æœº")
        else:
            print("   ğŸ”´ å›é¿: ç¼ è®ºä¿¡å·åå¼±ï¼Œå»ºè®®è°¨æ…")

        if hasattr(trend, 'value'):
            trend_str = trend.value
        else:
            trend_str = str(trend)

        if trend_str == "ä¸Šæ¶¨":
            print("   ğŸ“ˆ è¶‹åŠ¿: å½“å‰å¤„äºä¸Šæ¶¨è¶‹åŠ¿")
        elif trend_str == "ä¸‹è·Œ":
            print("   ğŸ“‰ è¶‹åŠ¿: å½“å‰å¤„äºä¸‹è·Œè¶‹åŠ¿")
        else:
            print("   ğŸ“Š è¶‹åŠ¿: å½“å‰å¤„äºç›˜æ•´çŠ¶æ€")

        print(f"\nğŸ“ {result.get('summary', 'åˆ†æå®Œæˆ')}")

    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŠ ç¼ è®ºåˆ†æç¤ºä¾‹")
    print("åŸºäºç¼ ä¸­è¯´ç¦…ç†è®ºçš„è‚¡ç¥¨æŠ€æœ¯åˆ†æ")
    print("=" * 60)

    # ç¤ºä¾‹è‚¡ç¥¨åˆ—è¡¨
    example_stocks = [
        "600519",  # è´µå·èŒ…å°
        "300750",  # å®å¾·æ—¶ä»£
        "000858",  # äº”ç²®æ¶²
    ]

    print("ğŸ“‹ å°†åˆ†æä»¥ä¸‹è‚¡ç¥¨:")
    for i, code in enumerate(example_stocks, 1):
        print(f"  {i}. {code}")

    print("\n" + "=" * 60)

    # é€ä¸ªåˆ†æ
    for code in example_stocks:
        analyze_stock_with_chanlun(code)
        print("\n" + "=" * 60)

    print("ğŸ‰ ç¼ è®ºåˆ†æç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ’¡ ç¼ è®ºæ ¸å¿ƒæ¦‚å¿µ:")
    print("â€¢ åˆ†å‹: å±€éƒ¨é«˜ä½ç‚¹ï¼Œæ˜¯æ„æˆç¬”çš„åŸºç¡€")
    print("â€¢ ç¬”: è¿æ¥ç›¸é‚»å¼‚ç±»åˆ†å‹çš„ç›´çº¿")
    print("â€¢ ä¸­æ¢: æŸçº§åˆ«èµ°åŠ¿ç±»å‹ä¸­ï¼Œè¢«è‡³å°‘ä¸‰ä¸ªè¿ç»­æ¬¡çº§åˆ«èµ°åŠ¿ç±»å‹æ‰€é‡å çš„éƒ¨åˆ†")
    print("â€¢ ä¹°å–ç‚¹: åŸºäºèµ°åŠ¿ç»“æ„å’Œä¸­æ¢å…³ç³»ç¡®å®šçš„äº¤æ˜“æ—¶æœº")
    print("â€¢ èƒŒé©°: ä»·æ ¼åˆ›æ–°é«˜/ä½ä½†åŠ›åº¦å‡å¼±ï¼Œé¢„ç¤ºè¶‹åŠ¿å¯èƒ½è½¬æŠ˜")


if __name__ == "__main__":
    main()
